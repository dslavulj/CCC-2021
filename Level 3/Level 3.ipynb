{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 5488)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "Data  = pd.read_csv(\"level_3_input/train.csv\", skiprows=1, header=None)\n",
    "\n",
    "Images = Data[:Data.shape[0]//2]\n",
    "Images = np.array(Images, dtype='float')\n",
    "\n",
    "\n",
    "Labels=Data[0][(Data.shape[0]//2):Data.shape[0]]\n",
    "Labels = np.array(Labels, dtype='float')\n",
    "\n",
    "print(Images.shape)\n",
    "print(Labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 5488)\n"
     ]
    }
   ],
   "source": [
    "Data_Test  = pd.read_csv(\"level_3_input/level_3_1.csv\", skiprows=1, header=None)\n",
    "\n",
    "Data_Test = Data_Test[:Data_Test.shape[0]]\n",
    "Data_Test = np.array(Data_Test, dtype='float')\n",
    "\n",
    "print(Data_Test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = Images.copy()\n",
    "x_test = Data_Test.copy()\n",
    "\n",
    "y_train = np.array(Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (10000, 28, 196, 1)\n",
      "10000 train samples\n",
      "3000 test samples\n"
     ]
    }
   ],
   "source": [
    "input_shape = (28,196, 1)\n",
    "\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "\n",
    "x_train = tf.reshape(x_train,[-1,28,196,1])\n",
    "x_test = tf.reshape(x_test,[-1,28,196,1])\n",
    "\n",
    "\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Images\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x1eb032462e0>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(x_train[3000])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 196, 16)       160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 98, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 98, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 98, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 49, 32)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 49, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 49, 64)         18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 3, 24, 64)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 3, 24, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 24, 128)        123008    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 3, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 3, 6, 128)         147584    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 3, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                147520    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 441,473\n",
      "Trainable params: 441,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(16, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Dropout(0.15),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Dropout(0.15),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Dropout(0.15),\n",
    "        layers.Conv2D(128, kernel_size=(3, 5), activation=\"relu\", padding=\"same\"),\n",
    "        layers.MaxPooling2D(pool_size=(1, 4)),\n",
    "        layers.Dropout(0.15),\n",
    "        layers.Conv2D(128, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"),\n",
    "        layers.Dropout(0.15),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "inp = keras.Input(shape=input_shape)\n",
    "\n",
    "x = layers.Conv2D(8, kernel_size=(3, 3), activation=\"relu\", padding=\"same\")(inp)\n",
    "xc = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = layers.Conv2D(16, kernel_size=(3, 3), activation=\"relu\", padding=\"same\")(xc)\n",
    "x = layers.Conv2D(16, kernel_size=(3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = x+layers.Conv2D(16, kernel_size=(1, 1), padding=\"same\")(xc)\n",
    "xc = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\", padding=\"same\")(xc)\n",
    "x = layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = x+layers.Conv2D(32, kernel_size=(1, 1), padding=\"same\")(xc)\n",
    "xc = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\", padding=\"same\")(xc)\n",
    "x = layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = x+layers.Conv2D(32, kernel_size=(1, 1), padding=\"same\")(xc)\n",
    "xc = layers.MaxPooling2D(pool_size=(1, 2))(x)\n",
    "x = layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\", padding=\"same\")(xc)\n",
    "x = layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = x+layers.Conv2D(64, kernel_size=(1, 1), padding=\"same\")(xc)\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.75)(x)\n",
    "\n",
    "out = layers.Dense(1, activation=\"softmax\")(x)\n",
    "\n",
    "model = keras.Model(inp, out)\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "TensorShape([10000, 28, 196])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0461 - mse: 0.0461\n",
      "Epoch 00001: val_loss improved from -inf to 0.02602, saving model to best.h5\n",
      "250/250 [==============================] - 17s 69ms/step - loss: 0.0461 - mse: 0.0461 - val_loss: 0.0260 - val_mse: 0.0260\n",
      "Epoch 2/30\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0195 - mse: 0.0195\n",
      "Epoch 00002: val_loss did not improve from 0.02602\n",
      "250/250 [==============================] - 17s 69ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0073 - val_mse: 0.0073\n",
      "Epoch 3/30\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0106 - mse: 0.0106\n",
      "Epoch 00003: val_loss did not improve from 0.02602\n",
      "250/250 [==============================] - 17s 69ms/step - loss: 0.0106 - mse: 0.0106 - val_loss: 0.0049 - val_mse: 0.0049\n",
      "Epoch 4/30\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0083 - mse: 0.0083\n",
      "Epoch 00004: val_loss did not improve from 0.02602\n",
      "250/250 [==============================] - 17s 68ms/step - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0042 - val_mse: 0.0042\n",
      "Epoch 5/30\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0070 - mse: 0.0070\n",
      "Epoch 00005: val_loss did not improve from 0.02602\n",
      "250/250 [==============================] - 17s 69ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0034 - val_mse: 0.0034\n",
      "Epoch 6/30\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0062 - mse: 0.0062\n",
      "Epoch 00006: val_loss did not improve from 0.02602\n",
      "250/250 [==============================] - 17s 70ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0030 - val_mse: 0.0030\n",
      "Epoch 7/30\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0056 - mse: 0.0056\n",
      "Epoch 00007: val_loss did not improve from 0.02602\n",
      "250/250 [==============================] - 17s 70ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0026 - val_mse: 0.0026\n",
      "Epoch 8/30\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0053 - mse: 0.0053\n",
      "Epoch 00008: val_loss did not improve from 0.02602\n",
      "250/250 [==============================] - 18s 71ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0023 - val_mse: 0.0023\n",
      "Epoch 9/30\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0049 - mse: 0.0049\n",
      "Epoch 00009: val_loss did not improve from 0.02602\n",
      "250/250 [==============================] - 18s 72ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0026 - val_mse: 0.0026\n",
      "Epoch 10/30\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 00010: val_loss did not improve from 0.02602\n",
      "250/250 [==============================] - 18s 71ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0023 - val_mse: 0.0023\n",
      "Epoch 11/30\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 00011: val_loss did not improve from 0.02602\n",
      "250/250 [==============================] - 18s 72ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0020 - val_mse: 0.0020\n",
      "Epoch 12/30\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 00012: val_loss did not improve from 0.02602\n",
      "250/250 [==============================] - 19s 76ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0021 - val_mse: 0.0021\n",
      "Epoch 13/30\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 00013: val_loss did not improve from 0.02602\n",
      "250/250 [==============================] - 18s 70ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0020 - val_mse: 0.0020\n",
      "Epoch 14/30\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 00014: val_loss did not improve from 0.02602\n",
      "250/250 [==============================] - 18s 71ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 15/30\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 00015: val_loss did not improve from 0.02602\n",
      "250/250 [==============================] - 17s 69ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0021 - val_mse: 0.0021\n",
      "Epoch 16/30\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0034 - mse: 0.0034\n",
      "Epoch 00016: val_loss did not improve from 0.02602\n",
      "250/250 [==============================] - 17s 69ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 17/30\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0033 - mse: 0.0033\n",
      "Epoch 00017: val_loss did not improve from 0.02602\n",
      "250/250 [==============================] - 18s 71ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 18/30\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0030 - mse: 0.0030\n",
      "Epoch 00018: val_loss did not improve from 0.02602\n",
      "250/250 [==============================] - 19s 74ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 19/30\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0028 - mse: 0.0028\n",
      "Epoch 00019: val_loss did not improve from 0.02602\n",
      "250/250 [==============================] - 18s 72ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 20/30\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0028 - mse: 0.0028\n",
      "Epoch 00020: val_loss did not improve from 0.02602\n",
      "250/250 [==============================] - 19s 74ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 21/30\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0027 - mse: 0.0027\n",
      "Epoch 00021: val_loss did not improve from 0.02602\n",
      "250/250 [==============================] - 18s 74ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 22/30\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0027 - mse: 0.0027\n",
      "Epoch 00022: val_loss did not improve from 0.02602\n",
      "250/250 [==============================] - 18s 70ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 23/30\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0027 - mse: 0.0027\n",
      "Epoch 00023: val_loss did not improve from 0.02602\n",
      "250/250 [==============================] - 18s 71ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 24/30\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0025 - mse: 0.0025\n",
      "Epoch 00024: val_loss did not improve from 0.02602\n",
      "250/250 [==============================] - 18s 71ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 25/30\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0026 - mse: 0.0026\n",
      "Epoch 00025: val_loss did not improve from 0.02602\n",
      "250/250 [==============================] - 19s 77ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 26/30\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0026 - mse: 0.0026\n",
      "Epoch 00026: val_loss did not improve from 0.02602\n",
      "250/250 [==============================] - 18s 73ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 27/30\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0025 - mse: 0.0025\n",
      "Epoch 00027: val_loss did not improve from 0.02602\n",
      "250/250 [==============================] - 18s 74ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 28/30\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0025 - mse: 0.0025\n",
      "Epoch 00028: val_loss did not improve from 0.02602\n",
      "250/250 [==============================] - 18s 70ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 29/30\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0026 - mse: 0.0026\n",
      "Epoch 00029: val_loss did not improve from 0.02602\n",
      "250/250 [==============================] - 18s 71ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 30/30\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0025 - mse: 0.0025\n",
      "Epoch 00030: val_loss did not improve from 0.02602\n",
      "250/250 [==============================] - 18s 71ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0011 - val_mse: 0.0011\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x1eb2b57e940>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "epochs = 30\n",
    "Check = keras.callbacks.ModelCheckpoint(\n",
    "    \"best.h5\", monitor=\"val_loss\", verbose=2, save_best_only=True,\n",
    "    save_weights_only=True, mode='max', save_freq='epoch',\n",
    ")\n",
    "\n",
    "Plateau = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3)\n",
    "\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.Adam(learning_rate=0.001), metrics=['mse'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2, callbacks=[Check, Plateau])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"best.h5\")\n",
    "\n",
    "y_hat = model.predict(x_test)\n",
    "rounded = tf.cast(tf.math.round(y_hat), tf.int32)\n",
    "np.savetxt(\"level_3_output/Level_3_1_Result.csv\", rounded, fmt='%i', delimiter=\"\\n\", )\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}