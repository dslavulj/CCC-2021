{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11200, 2352)\n"
     ]
    }
   ],
   "source": [
    "Data  = pd.read_csv(\"level_2_Input/train.csv\", skiprows=1, header=None)\n",
    "\n",
    "Images = Data[:Data.shape[0]//2]\n",
    "Images = np.array(Images, dtype='float')\n",
    "\n",
    "\n",
    "Labels=Data[0][(Data.shape[0]//2):Data.shape[0]]\n",
    "Labels = np.array(Labels, dtype='int')\n",
    "\n",
    "print(Data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 2352)\n"
     ]
    }
   ],
   "source": [
    "Data_Test  = pd.read_csv(\"level_2_Input/level_2_2.csv\", skiprows=1, header=None)\n",
    "\n",
    "Data_Test = Data_Test[:Data_Test.shape[0]]\n",
    "Data_Test = np.array(Data_Test, dtype='float')\n",
    "\n",
    "print(Data_Test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (5600, 28, 84, 1)\n",
      "5600 train samples\n",
      "3000 test samples\n",
      "(5600, 2)\n"
     ]
    }
   ],
   "source": [
    "num_classes = 2\n",
    "input_shape = (28,84, 1)\n",
    "\n",
    "x_train = Images.copy()\n",
    "y_train = np.array(Labels)\n",
    "x_test = Data_Test.copy()\n",
    "\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "x_train = tf.reshape(x_train,[-1,28,84])\n",
    "x_test = tf.reshape(x_test,[-1,28,84])\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")\n",
    "\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x1b99c085b50>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(x_train[3000])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 28, 84, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 28, 84, 8)    80          input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 14, 42, 8)    0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 14, 42, 16)   1168        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 14, 42, 16)   2320        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 14, 42, 16)   144         max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_4 (TensorFlow [(None, 14, 42, 16)] 0           conv2d_15[0][0]                  \n",
      "                                                                 conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 7, 21, 16)    0           tf_op_layer_AddV2_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 7, 21, 32)    4640        max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 7, 21, 32)    9248        conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 7, 21, 32)    544         max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_5 (TensorFlow [(None, 7, 21, 32)]  0           conv2d_18[0][0]                  \n",
      "                                                                 conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 3, 10, 32)    0           tf_op_layer_AddV2_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 3, 10, 32)    9248        max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 3, 10, 32)    9248        conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 3, 10, 32)    1056        max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_6 (TensorFlow [(None, 3, 10, 32)]  0           conv2d_21[0][0]                  \n",
      "                                                                 conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 3, 5, 32)     0           tf_op_layer_AddV2_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 3, 5, 64)     18496       max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 3, 5, 64)     36928       conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 3, 5, 64)     2112        max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_7 (TensorFlow [(None, 3, 5, 64)]   0           conv2d_24[0][0]                  \n",
      "                                                                 conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 960)          0           tf_op_layer_AddV2_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           61504       flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 64)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            65          dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 156,801\n",
      "Trainable params: 156,801\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inp = keras.Input(shape=input_shape)\n",
    "\n",
    "\n",
    "x = layers.Conv2D(8, kernel_size=(3, 3), activation=\"relu\", padding=\"same\")(inp)\n",
    "xc = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = layers.Conv2D(16, kernel_size=(3, 3), activation=\"relu\", padding=\"same\")(xc)\n",
    "x = layers.Conv2D(16, kernel_size=(3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = x+layers.Conv2D(16, kernel_size=(1, 1), padding=\"same\")(xc)\n",
    "xc = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\", padding=\"same\")(xc)\n",
    "x = layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = x+layers.Conv2D(32, kernel_size=(1, 1), padding=\"same\")(xc)\n",
    "xc = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\", padding=\"same\")(xc)\n",
    "x = layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = x+layers.Conv2D(32, kernel_size=(1, 1), padding=\"same\")(xc)\n",
    "xc = layers.MaxPooling2D(pool_size=(1, 2))(x)\n",
    "x = layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\", padding=\"same\")(xc)\n",
    "x = layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = x+layers.Conv2D(64, kernel_size=(1, 1), padding=\"same\")(xc)\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.75)(x)\n",
    "\n",
    "out = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model = keras.Model(inp, out)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "139/140 [============================>.] - ETA: 0s - loss: 0.2101 - accuracy: 0.9029\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.81161, saving model to best.h5\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.2106 - accuracy: 0.9025 - val_loss: 0.4261 - val_accuracy: 0.8116\n",
      "Epoch 2/30\n",
      "139/140 [============================>.] - ETA: 0s - loss: 0.1926 - accuracy: 0.9218\n",
      "Epoch 00002: val_accuracy improved from 0.81161 to 0.86964, saving model to best.h5\n",
      "140/140 [==============================] - 5s 38ms/step - loss: 0.1931 - accuracy: 0.9217 - val_loss: 0.4096 - val_accuracy: 0.8696\n",
      "Epoch 3/30\n",
      "139/140 [============================>.] - ETA: 0s - loss: 0.1387 - accuracy: 0.9510\n",
      "Epoch 00003: val_accuracy did not improve from 0.86964\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.1383 - accuracy: 0.9511 - val_loss: 0.4904 - val_accuracy: 0.8420\n",
      "Epoch 4/30\n",
      "139/140 [============================>.] - ETA: 0s - loss: 0.1063 - accuracy: 0.9604\n",
      "Epoch 00004: val_accuracy did not improve from 0.86964\n",
      "140/140 [==============================] - 5s 35ms/step - loss: 0.1060 - accuracy: 0.9605 - val_loss: 0.6566 - val_accuracy: 0.7839\n",
      "Epoch 5/30\n",
      "139/140 [============================>.] - ETA: 0s - loss: 0.0842 - accuracy: 0.9735\n",
      "Epoch 00005: val_accuracy improved from 0.86964 to 0.87321, saving model to best.h5\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.0847 - accuracy: 0.9734 - val_loss: 0.6203 - val_accuracy: 0.8732\n",
      "Epoch 6/30\n",
      "139/140 [============================>.] - ETA: 0s - loss: 0.0739 - accuracy: 0.9748\n",
      "Epoch 00006: val_accuracy improved from 0.87321 to 0.87768, saving model to best.h5\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.0737 - accuracy: 0.9748 - val_loss: 0.3879 - val_accuracy: 0.8777\n",
      "Epoch 7/30\n",
      "139/140 [============================>.] - ETA: 0s - loss: 0.0800 - accuracy: 0.9755\n",
      "Epoch 00007: val_accuracy improved from 0.87768 to 0.90714, saving model to best.h5\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.0797 - accuracy: 0.9757 - val_loss: 0.2937 - val_accuracy: 0.9071\n",
      "Epoch 8/30\n",
      "139/140 [============================>.] - ETA: 0s - loss: 0.0636 - accuracy: 0.9840\n",
      "Epoch 00008: val_accuracy did not improve from 0.90714\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.0632 - accuracy: 0.9842 - val_loss: 0.6283 - val_accuracy: 0.8473\n",
      "Epoch 9/30\n",
      "139/140 [============================>.] - ETA: 0s - loss: 0.0437 - accuracy: 0.9822\n",
      "Epoch 00009: val_accuracy did not improve from 0.90714\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.0436 - accuracy: 0.9821 - val_loss: 2.0657 - val_accuracy: 0.8080\n",
      "Epoch 10/30\n",
      "139/140 [============================>.] - ETA: 0s - loss: 0.0548 - accuracy: 0.9829\n",
      "Epoch 00010: val_accuracy did not improve from 0.90714\n",
      "140/140 [==============================] - 5s 35ms/step - loss: 0.0546 - accuracy: 0.9830 - val_loss: 0.9923 - val_accuracy: 0.8786\n",
      "Epoch 11/30\n",
      "139/140 [============================>.] - ETA: 0s - loss: 0.0110 - accuracy: 0.9971\n",
      "Epoch 00011: val_accuracy did not improve from 0.90714\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 0.0111 - accuracy: 0.9971 - val_loss: 1.1426 - val_accuracy: 0.8661\n",
      "Epoch 12/30\n",
      "139/140 [============================>.] - ETA: 0s - loss: 0.0056 - accuracy: 0.9982\n",
      "Epoch 00012: val_accuracy did not improve from 0.90714\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 1.2420 - val_accuracy: 0.8661\n",
      "Epoch 13/30\n",
      "139/140 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9996\n",
      "Epoch 00013: val_accuracy did not improve from 0.90714\n",
      "140/140 [==============================] - 5s 35ms/step - loss: 0.0036 - accuracy: 0.9996 - val_loss: 1.2934 - val_accuracy: 0.8696\n",
      "Epoch 14/30\n",
      "139/140 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9996\n",
      "Epoch 00014: val_accuracy did not improve from 0.90714\n",
      "140/140 [==============================] - 5s 38ms/step - loss: 0.0033 - accuracy: 0.9996 - val_loss: 1.3025 - val_accuracy: 0.8705\n",
      "Epoch 15/30\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 0.9996\n",
      "Epoch 00015: val_accuracy did not improve from 0.90714\n",
      "140/140 [==============================] - 5s 37ms/step - loss: 0.0038 - accuracy: 0.9996 - val_loss: 1.3167 - val_accuracy: 0.8705\n",
      "Epoch 16/30\n",
      "139/140 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 00016: val_accuracy did not improve from 0.90714\n",
      "140/140 [==============================] - 5s 37ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.3257 - val_accuracy: 0.8705\n",
      "Epoch 17/30\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 00017: val_accuracy did not improve from 0.90714\n",
      "140/140 [==============================] - 5s 38ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.3271 - val_accuracy: 0.8705\n",
      "Epoch 18/30\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9998\n",
      "Epoch 00018: val_accuracy did not improve from 0.90714\n",
      "140/140 [==============================] - 7s 47ms/step - loss: 0.0031 - accuracy: 0.9998 - val_loss: 1.3284 - val_accuracy: 0.8705\n",
      "Epoch 19/30\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 0.9998\n",
      "Epoch 00019: val_accuracy did not improve from 0.90714\n",
      "140/140 [==============================] - 6s 43ms/step - loss: 0.0028 - accuracy: 0.9998 - val_loss: 1.3298 - val_accuracy: 0.8705\n",
      "Epoch 20/30\n",
      "139/140 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 0.9998\n",
      "Epoch 00020: val_accuracy did not improve from 0.90714\n",
      "140/140 [==============================] - 5s 37ms/step - loss: 0.0032 - accuracy: 0.9998 - val_loss: 1.3300 - val_accuracy: 0.8705\n",
      "Epoch 21/30\n",
      "139/140 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 00021: val_accuracy did not improve from 0.90714\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.3302 - val_accuracy: 0.8705\n",
      "Epoch 22/30\n",
      "139/140 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 00022: val_accuracy did not improve from 0.90714\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.3303 - val_accuracy: 0.8705\n",
      "Epoch 23/30\n",
      "139/140 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9998\n",
      "Epoch 00023: val_accuracy did not improve from 0.90714\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.0028 - accuracy: 0.9998 - val_loss: 1.3303 - val_accuracy: 0.8705\n",
      "Epoch 24/30\n",
      "139/140 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 00024: val_accuracy did not improve from 0.90714\n",
      "140/140 [==============================] - 5s 37ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.3303 - val_accuracy: 0.8705\n",
      "Epoch 25/30\n",
      "139/140 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 00025: val_accuracy did not improve from 0.90714\n",
      "140/140 [==============================] - 5s 37ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.3304 - val_accuracy: 0.8705\n",
      "Epoch 26/30\n",
      "139/140 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9996\n",
      "Epoch 00026: val_accuracy did not improve from 0.90714\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.0024 - accuracy: 0.9996 - val_loss: 1.3304 - val_accuracy: 0.8705\n",
      "Epoch 27/30\n",
      "139/140 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9998\n",
      "Epoch 00027: val_accuracy did not improve from 0.90714\n",
      "140/140 [==============================] - 5s 37ms/step - loss: 0.0031 - accuracy: 0.9998 - val_loss: 1.3304 - val_accuracy: 0.8705\n",
      "Epoch 28/30\n",
      "139/140 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9993\n",
      "Epoch 00028: val_accuracy did not improve from 0.90714\n",
      "140/140 [==============================] - 5s 36ms/step - loss: 0.0034 - accuracy: 0.9993 - val_loss: 1.3304 - val_accuracy: 0.8705\n",
      "Epoch 29/30\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 00029: val_accuracy did not improve from 0.90714\n",
      "140/140 [==============================] - 5s 35ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.3304 - val_accuracy: 0.8705\n",
      "Epoch 30/30\n",
      "139/140 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 00030: val_accuracy did not improve from 0.90714\n",
      "140/140 [==============================] - 5s 37ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.3304 - val_accuracy: 0.8705\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x1b99c0abc70>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "epochs = 30\n",
    "Check = keras.callbacks.ModelCheckpoint(\n",
    "    \"best.h5\", monitor='val_accuracy', verbose=2, save_best_only=True,\n",
    "    save_weights_only=True, mode='max', save_freq='epoch',\n",
    ")\n",
    "\n",
    "Plateau = keras.callbacks.ReduceLROnPlateau(monitor=\"val_accuracy\", factor=0.1, patience=3)\n",
    "\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=0.003), metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x_train, tf.math.argmax(y_train, -1), batch_size=batch_size, epochs=epochs, validation_split=0.2, callbacks=[Check, Plateau])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"best.h5\")\n",
    "\n",
    "y_hat = model.predict(x_test)\n",
    "rounded = tf.cast(tf.math.round(y_hat), tf.int32)\n",
    "np.savetxt(\"level_2_output/level_2_2_Result.csv\", rounded, fmt='%i', delimiter=\"\\n\", )\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}